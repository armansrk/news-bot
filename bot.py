import os
import time
import requests
import feedparser
from googletrans import Translator
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª
BOT_TOKEN = os.getenv("BOT_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
SEEN_FILE = "seen.txt"

RSS_FEEDS = [
    "https://arzdigital.com/feed/",
    "https://www.coindesk.com/feed/",
    "https://cointelegraph.com/rss",
    "https://cryptoslate.com/feed/",
    "https://decrypt.co/feed",
]

HEADERS = {"User-Agent": "Mozilla/5.0 (NewsBot)"}

# ØªØ±Ø¬Ù…Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ
def translate_to_persian(text: str) -> str:
    translator = Translator()
    translated = translator.translate(text, src='en', dest='fa')
    return translated.text

# Ø®ÙˆØ§Ù†Ø¯Ù†/Ù†ÙˆØ´ØªÙ† seen.txt
def load_seen() -> set:
    if not os.path.exists(SEEN_FILE):
        return set()
    with open(SEEN_FILE, "r", encoding="utf-8") as f:
        return set(line.strip() for line in f if line.strip())

def save_seen(seen: set):
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        for url in sorted(seen):
            f.write(url + "\n")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ù„Ø§ØµÙ‡ Ø§Ø² URL
def extract_summary_from_url(url: str, max_chars: int = 420) -> str:
    try:
        r = requests.get(url, headers=HEADERS, timeout=20)
        r.raise_for_status()

        soup = BeautifulSoup(r.text, "html.parser")
        for tag in soup(["script", "style", "noscript"]):
            tag.decompose()

        paragraphs = [p.get_text(" ", strip=True) for p in soup.find_all("p")]
        text = " ".join([p for p in paragraphs if p and len(p) > 30])
        text = re.sub(r"\s+", " ", text).strip()

        if not text:
            return "Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

        summary = text[:max_chars]
        if len(text) > max_chars:
            summary += "â€¦"
        return summary

    except Exception:
        return "Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµÙˆÛŒØ± Ø§Ø² ØµÙØ­Ù‡
def extract_image_from_url(url: str) -> str:
    try:
        r = requests.get(url, headers=HEADERS, timeout=20)
        r.raise_for_status()

        soup = BeautifulSoup(r.text, "html.parser")
        img_tag = soup.find("img")  # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† ØªÚ¯ img
        if img_tag:
            img_url = img_tag.get("src")
            img_url = urljoin(url, img_url)  # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ Ø¢Ø¯Ø±Ø³ Ú©Ø§Ù…Ù„ ØªØµÙˆÛŒØ± Ø±Ø§ Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…
            return img_url
        return ""
    except Exception:
        return ""

# Ú¯Ø±ÙØªÙ† Ø§Ø®Ø¨Ø§Ø± Ø§Ø² RSS
def get_news_from_rss():
    items = []
    for feed_url in RSS_FEEDS:
        try:
            feed = feedparser.parse(feed_url)
            for entry in feed.entries[:40]:
                title = getattr(entry, "title", "").strip()
                link = getattr(entry, "link", "").strip()

                if title and link:
                    items.append({"title": title, "link": link})

        except Exception:
            continue
    return items

# Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… (Ø´Ø§Ù…Ù„ ØªØµÙˆÛŒØ±)
def send_telegram_message_with_image(text: str, img_url: str):
    api_url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto"
    payload = {
        "chat_id": CHANNEL_ID,
        "caption": text,
        "parse_mode": "HTML"
    }
    files = {"photo": requests.get(img_url).content} if img_url else {}
    r = requests.post(api_url, data=payload, files=files, timeout=20)
    if r.status_code == 200:
        print(f"âœ… Ù¾ÛŒØ§Ù… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯: {text}")
    else:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…: {r.status_code} - {r.text}")

# Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª
def job():
    if not BOT_TOKEN or not CHANNEL_ID:
        raise RuntimeError("BOT_TOKEN Ùˆ CHANNEL_ID Ø±Ø§ Ø¯Ø± GitHub Secrets Ø³Øª Ú©Ù†.")

    seen = load_seen()
    news = get_news_from_rss()

    sent = 0
    for item in news:
        url = item["link"]
        title = item["title"]

        if url in seen:
            continue

        summary = extract_summary_from_url(url)
        translated_summary = translate_to_persian(summary)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØµÙˆÛŒØ± Ø§Ø² Ø®Ø¨Ø±
        img_url = extract_image_from_url(url)

        # Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØªØµÙˆÛŒØ±
        message = (
            f"ğŸ”¹ <b>{title}</b>\n\n"
            f"{translated_summary}\n\n"
            f"ğŸ”— <a href='{url}'>Ø§Ø¯Ø§Ù…Ù‡ Ø®Ø¨Ø±</a>"
        )

        send_telegram_message_with_image(message, img_url)
        seen.add(url)
        sent += 1
        time.sleep(1)

    save_seen(seen)
    print(f"âœ… {sent} Ø®Ø¨Ø± Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯ (Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±)")

# Ø§Ø¬Ø±Ø§
if __name__ == "__main__":
    job()
